@misc{li_johnson_karpathy,
  author        = {Li, Fei-Fei and Johnson, Justin and Karpathy, Andrej},
  title         = {Lecture notes in CS231},
  month         = {Feb},
  year          = {2016},
  publisher={Stanford}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Images
@misc{rosebrock_2017, title={Intersection over Union (IoU) for object detection}, url={https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/}, journal={PyImageSearch}, author={Rosebrock, Adrian}, year={2017}, month={Nov}}




% TIME SERIES FORECASTING (TSF)


% Survey: https://arxiv.org/abs/2002.12478
@inproceedings{Wen_2021, series={IJCAI-2021},
   title={Time Series Data Augmentation for Deep Learning: A Survey},
   url={http://dx.doi.org/10.24963/ijcai.2021/631},
   DOI={10.24963/ijcai.2021/631},
   booktitle={Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence},
   publisher={International Joint Conferences on Artificial Intelligence Organization},
   author={Wen, Qingsong and Sun, Liang and Yang, Fan and Song, Xiaomin and Gao, Jingkun and Wang, Xue and Xu, Huan},
   year={2021},
   month=aug, pages={4653–4660},
   collection={IJCAI-2021} }


% Dominant Shuffle: https://arxiv.org/abs/2405.16456
@misc{zhao2024dominantshufflesimplepowerful,
      title={Dominant Shuffle: A Simple Yet Powerful Data Augmentation for Time-series Prediction}, 
      author={Kai Zhao and Zuojie He and Alex Hung and Dan Zeng},
      year={2024},
      eprint={2405.16456},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.16456}, 
}

% FreqMixMax: https://arxiv.org/abs/2302.09292
@misc{chen2023fraugfrequencydomainaugmentation,
      title={FrAug: Frequency Domain Augmentation for Time Series Forecasting}, 
      author={Muxi Chen and Zhijian Xu and Ailing Zeng and Qiang Xu},
      year={2023},
      eprint={2302.09292},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.09292}, 
}

% STAug: https://arxiv.org/abs/2303.14254
@misc{zhang2023diversecoherentaugmentationtimeseries,
      title={Towards Diverse and Coherent Augmentation for Time-Series Forecasting}, 
      author={Xiyuan Zhang and Ranak Roy Chowdhury and Jingbo Shang and Rajesh Gupta and Dezhi Hong},
      year={2023},
      eprint={2303.14254},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.14254}, 
}

% FreqPool: file:///Users/jafar_bakhshaliyev/Downloads/Results/25863-Article%20Text-29926-1-2-20230626%20(7).pdf
@inproceedings{freqpool,
  title={Supervised contrastive few-shot learning for high-frequency time series},
  author={Chen, Xi and Ge, Cheng and Wang, Ming and Wang, Jin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={6},
  pages={7069--7077},
  year={2023}
}

% FreqAdd: https://arxiv.org/abs/2206.08496
@misc{freqadd,
      title={Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency}, 
      author={Xiang Zhang and Ziyuan Zhao and Theodoros Tsiligkaridis and Marinka Zitnik},
      year={2022},
      eprint={2206.08496},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.08496}, 
}

@misc{arabi2024wavemaskmixexploringwaveletbasedaugmentations,
      title={Wave-Mask/Mix: Exploring Wavelet-Based Augmentations for Time Series Forecasting}, 
      author={Dona Arabi and Jafar Bakhshaliyev and Ayse Coskuner and Kiran Madhusudhanan and Kami Serdar Uckardes},
      year={2024},
      eprint={2408.10951},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.10951}, 
}

@misc{gao2021robusttadrobusttimeseries,
      title={RobustTAD: Robust Time Series Anomaly Detection via Decomposition and Convolutional Neural Networks}, 
      author={Jingkun Gao and Xiaomin Song and Qingsong Wen and Pichao Wang and Liang Sun and Huan Xu},
      year={2021},
      eprint={2002.09545},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.09545}, 
}



% TimeGAN
@inproceedings{timegan,
	author = {Yoon, Jinsung and Jarrett, Daniel and van der Schaar, Mihaela},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Time-series Generative Adversarial Networks},
	url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf},
	volume = {32},
	year = {2019},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf}}

% Upsample
@article{upsample,
  title={Data augmentation for univariate time series forecasting with neural networks},
  author={Semenoglou, Artemios-Anargyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
  journal={Pattern Recognition},
  volume={134},
  pages={109132},
  year={2023},
  publisher={Elsevier}
}


% ASD
@inproceedings{asd,
  title={Generating synthetic time series to augment sparse datasets},
  author={Forestier, Germain and Petitjean, Fran{\c{c}}ois and Dau, Hoang Anh and Webb, Geoffrey I and Keogh, Eamonn},
  booktitle={2017 IEEE international conference on data mining (ICDM)},
  pages={865--870},
  year={2017},
  organization={IEEE}
}

% MBB
@article{mbb,
  title={Improving the accuracy of global forecasting models using time series data augmentation},
  author={Bandara, Kasun and Hewamalage, Hansika and Liu, Yuan-Hao and Kang, Yanfei and Bergmeir, Christoph},
  journal={Pattern Recognition},
  volume={120},
  pages={108148},
  year={2021},
  publisher={Elsevier}
}

% MBB 2
@article{BERGMEIR2016303,
	abstract = {Exponential smoothing is one of the most popular forecasting methods. We present a technique for the bootstrap aggregation (bagging) of exponential smoothing methods, which results in significant improvements in the forecasts. The bagging uses a Box--Cox transformation followed by an STL decomposition to separate the time series into the trend, seasonal part, and remainder. The remainder is then bootstrapped using a moving block bootstrap, and a new series is assembled using this bootstrapped remainder. An ensemble of exponential smoothing models is then estimated on the bootstrapped series, and the resulting point forecasts are combined. We evaluate this new method on the M3 data set, and show that it outperforms the original exponential smoothing models consistently. On the monthly data, we achieve better results than any of the original M3 participants.},
	author = {Christoph Bergmeir and Rob J. Hyndman and Jos{\'e} M. Ben{\'\i}tez},
	doi = {https://doi.org/10.1016/j.ijforecast.2015.07.002},
	issn = {0169-2070},
	journal = {International Journal of Forecasting},
	keywords = {Bagging, Bootstrapping, Exponential smoothing, STL decomposition},
	number = {2},
	pages = {303-312},
	title = {Bagging exponential smoothing methods using STL decomposition and Box--Cox transformation},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207015001120},
	volume = {32},
	year = {2016},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0169207015001120},
	bdsk-url-2 = {https://doi.org/10.1016/j.ijforecast.2015.07.002}}



















%Onemsiz random noise: https://arxiv.org/abs/1905.13628
@misc{wen2019timeseriesanomalydetection,
      title={Time Series Anomaly Detection Using Convolutional Neural Networks and Transfer Learning}, 
      author={Tailai Wen and Roy Keyes},
      year={2019},
      eprint={1905.13628},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1905.13628}, 
}

%Onemsiz window cropping: https://arxiv.org/abs/1603.06995
@misc{cui2016multiscaleconvolutionalneuralnetworks,
      title={Multi-Scale Convolutional Neural Networks for Time Series Classification}, 
      author={Zhicheng Cui and Wenlin Chen and Yixin Chen},
      year={2016},
      eprint={1603.06995},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1603.06995}, 
}
% STL
@article{cleveland1990stl,
  title={STL: A seasonal-trend decomposition},
  author={Cleveland, Robert B and Cleveland, William S and McRae, Jean E and Terpenning, Irma},
  journal={J. Off. Stat},
  year={1990}
}

% EMD
@article{huang1998empirical,
  title={The empirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis},
  author={Huang, Norden E and Shen, Zheng and Long, Steven R and Wu, Manli C and Shih, Hsing H and Zheng, Quanan and Yen, Nai-Chyuan and Tung, Chi Chao and Liu, Henry H},
  journal={Proceedings of the Royal Society of London. Series A: mathematical, physical and engineering sciences},
  year={1998}
}

% STAUG eary approaches
@inproceedings{nam2020data,
  title={Data augmentation using empirical mode decomposition on neural networks to classify impact noise in vehicle},
  author={Nam, Gue-Hwan and Bu, Seok-Jun and Park, Na-Mu and Seo, Jae-Yong and Jo, Hyeon-Cheol and Jeong, Won-Tae},
  booktitle={ICASSP},
  year={2020}
}

% Mixup
@misc{zhang2018mixupempiricalriskminimization,
      title={mixup: Beyond Empirical Risk Minimization}, 
      author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
      year={2018},
      eprint={1710.09412},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1710.09412}, 
}


% iTransformer model which we do not use.
@misc{liu2024itransformerinvertedtransformerseffective,
      title={iTransformer: Inverted Transformers Are Effective for Time Series Forecasting}, 
      author={Yong Liu and Tengge Hu and Haoran Zhang and Haixu Wu and Shiyu Wang and Lintao Ma and Mingsheng Long},
      year={2024},
      eprint={2310.06625},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.06625}, 
}



% TIME SERIES CLASSIFICATION (TSC)

% InceptionTime 
@article{Ismail_Fawaz_2020,
   title={InceptionTime: Finding AlexNet for time series classification},
   volume={34},
   ISSN={1573-756X},
   url={http://dx.doi.org/10.1007/s10618-020-00710-y},
   DOI={10.1007/s10618-020-00710-y},
   number={6},
   journal={Data Mining and Knowledge Discovery},
   publisher={Springer Science and Business Media LLC},
   author={Ismail Fawaz, Hassan and Lucas, Benjamin and Forestier, Germain and Pelletier, Charlotte and Schmidt, Daniel F. and Weber, Jonathan and Webb, Geoffrey I. and Idoumghar, Lhassane and Muller, Pierre-Alain and Petitjean, François},
   year={2020},
   month=sep, pages={1936–1962} }








% Survey for multivariate TSC
@misc{ilbert2024dataaugmentationmultivariatetime,
      title={Data Augmentation for Multivariate Time Series Classification: An Experimental Study}, 
      author={Romain Ilbert and Thai V. Hoang and Zonghua Zhang},
      year={2024},
      eprint={2406.06518},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.06518}, 
}




% Survey for univariate TSC
@misc{gao2024dataaugmentationtimeseriesclassification,
      title={Data Augmentation for Time-Series Classification: An Extensive Empirical Study and Comprehensive Survey}, 
      author={Zijun Gao and Haibao Liu and Lingbo Li},
      year={2024},
      eprint={2310.10060},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.10060}, 
}


% survey plusone 2025
@article{10.1371/journal.pone.0315343,
	abstract = {Recent advancements in hardware technology have spurred a surge in the popularity and ubiquity of wearable sensors, opening up new applications within the medical domain. This proliferation has resulted in a notable increase in the availability of Time Series (TS) data characterizing behavioral or physiological information from the patient, leading to initiatives toward leveraging machine learning and data analysis techniques. Nonetheless, the complexity and time required for collecting data remain significant hurdles, limiting dataset sizes and hindering the effectiveness of machine learning. Data Augmentation (DA) stands out as a prime solution, facilitating the generation of synthetic data to address challenges associated with acquiring medical data. DA has shown to consistently improve performances when images are involved. As a result, investigations have been carried out to check DA for TS, in particular for TS classification. However, the current state of DA in TS classification faces challenges, including methodological taxonomies restricted to the univariate case, insufficient direction to select suitable DA methods and a lack of conclusive evidence regarding the amount of synthetic data required to attain optimal outcomes. This paper conducts a comprehensive survey and experiments on DA techniques for TS and their application to TS classification. We propose an updated taxonomy spanning across three families of Time Series Data Augmentation (TSDA): Random Transformation (RT), Pattern Mixing (PM), and Generative Models (GM). Additionally, we empirically evaluate 12 TSDA methods across diverse datasets used in medical-related applications, including OPPORTUNITY and HAR for Human Activity Recognition, DEAP for emotion recognition, BioVid Heat Pain Database (BVDB), and PainMonit Database (PMDB) for pain recognition. Through comprehensive experimental analysis, we identify the most optimal DA techniques and provide recommendations for researchers regarding the generation of synthetic data to maximize outcomes from DA methods. Our findings show that despite their simplicity, DA methods of the RT family are the most consistent in increasing performances compared to not using any augmentation.},
	author = {Hasan, Md Abid AND Li, Fr{\'e}d{\'e}ric AND Gouverneur, Philip AND Piet, Artur AND Grzegorzek, Marcin},
	doi = {10.1371/journal.pone.0315343},
	journal = {PLOS ONE},
	month = {03},
	number = {3},
	pages = {1-38},
	publisher = {Public Library of Science},
	title = {A comprehensive survey and comparative analysis of time series data augmentation in medical wearable computing},
	url = {https://doi.org/10.1371/journal.pone.0315343},
	volume = {20},
	year = {2025},
	bdsk-url-1 = {https://doi.org/10.1371/journal.pone.0315343}}




% MiniRocket used for univariate
@inproceedings{Dempster_2021, series={KDD ’21},
   title={MiniRocket: A Very Fast (Almost) Deterministic Transform for Time Series Classification},
   url={http://dx.doi.org/10.1145/3447548.3467231},
   DOI={10.1145/3447548.3467231},
   booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery; Data Mining},
   publisher={ACM},
   author={Dempster, Angus and Schmidt, Daniel F. and Webb, Geoffrey I.},
   year={2021},
   month=aug, pages={248–257},
   collection={KDD ’21} }


% MultiRocket what used for multivariate
@misc{tan2022multirocketmultiplepoolingoperators,
      title={MultiRocket: Multiple pooling operators and transformations for fast and effective time series classification}, 
      author={Chang Wei Tan and Angus Dempster and Christoph Bergmeir and Geoffrey I. Webb},
      year={2022},
      eprint={2102.00457},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2102.00457}, 
}


% Rocket 
@article{Dempster_2020,
   title={ROCKET: exceptionally fast and accurate time series classification using random convolutional kernels},
   volume={34},
   ISSN={1573-756X},
   url={http://dx.doi.org/10.1007/s10618-020-00701-z},
   DOI={10.1007/s10618-020-00701-z},
   number={5},
   journal={Data Mining and Knowledge Discovery},
   publisher={Springer Science and Business Media LLC},
   author={Dempster, Angus and Petitjean, François and Webb, Geoffrey I.},
   year={2020},
   month=jul, pages={1454–1495} }

% Augmentation methods:

%  Jittering, Rotation (Iwana),  Scaling, Magnitude Warping (Iwana),  Permutation,  Random Permutation, Time Warping.
@inproceedings{Um_2017, series={ICMI ’17},
   title={Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks},
   url={http://dx.doi.org/10.1145/3136755.3136817},
   DOI={10.1145/3136755.3136817},
   booktitle={Proceedings of the 19th ACM International Conference on Multimodal Interaction},
   publisher={ACM},
   author={Um, Terry T. and Pfister, Franz M. J. and Pichler, Daniel and Endo, Satoshi and Lang, Muriel and Hirche, Sandra and Fietzek, Urban and Kulić, Dana},
   year={2017},
   month=nov, collection={ICMI ’17} }


% Permutation Random Permutation
@inbook{Pan2020,
	abstract = {Deep learning has become the technology that gets the most attention in recent years owing to its admirable performance compared to the conventional methods in a series of tasks. Though its application in electrocardiogram (ECG) analysis has enhanced the understanding and the applicability of many disease diagnosis in clinic, lack of annotated data hampers the deep learning-based ECG analysis as large amount of data is required for a well-performed deep learning model. Data augmentation, which refers to the procedure that enriches the dataset by introducing unobserved samples, plays an important role in this respect. Despite the successful usage of data augmentation in the image-based deep learning analysis, its application in one-dimensional physiological signals, such as ECG, is still limited. In this chapter, we summarize the data augmentation methods applicable for ECG analysis and examine their performance on a task for detecting atrial fibrillation (AF).},
	address = {Singapore},
	author = {Pan, Qing and Li, Xinyi and Fang, Luping},
	booktitle = {Feature Engineering and Computational Intelligence in ECG Monitoring},
	doi = {10.1007/978-981-15-3824-7_6},
	editor = {Liu, Chengyu and Li, Jianqing},
	isbn = {978-981-15-3824-7},
	pages = {91--111},
	publisher = {Springer Singapore},
	title = {Data Augmentation for Deep Learning-Based ECG Analysis},
	url = {https://doi.org/10.1007/978-981-15-3824-7_6},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1007/978-981-15-3824-7_6}}

% window slicing, window warping
@inproceedings{leguennec:halshs-01357973,
  TITLE = {{Data Augmentation for Time Series Classification using Convolutional Neural Networks}},
  AUTHOR = {Le Guennec, Arthur and Malinowski, Simon and Tavenard, Romain},
  URL = {https://shs.hal.science/halshs-01357973},
  BOOKTITLE = {{ECML/PKDD Workshop on Advanced Analytics and Learning on Temporal Data}},
  ADDRESS = {Riva Del Garda, Italy},
  YEAR = {2016},
  MONTH = Sep,
  KEYWORDS = {time series ; convolutional neural networks},
  PDF = {https://shs.hal.science/halshs-01357973v1/file/AALTD16_paper_9.pdf},
  HAL_ID = {halshs-01357973},
  HAL_VERSION = {v1},
}

% Time warping
@inproceedings{Park_2019, series={interspeech_2019},
   title={SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition},
   url={http://dx.doi.org/10.21437/Interspeech.2019-2680},
   DOI={10.21437/interspeech.2019-2680},
   booktitle={Interspeech 2019},
   publisher={ISCA},
   author={Park, Daniel S. and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D. and Le, Quoc V.},
   year={2019},
   month=sep, collection={interspeech_2019} }


% spawner
@article{s20010098,
	abstract = {In this paper, a novel data augmentation method for time-series classification is proposed. In the introduced method, a new time-series is obtained in warped space between suboptimally aligned input examples of different lengths. Specifically, the alignment is carried out constraining the warping path and reducing its flexibility. It is shown that the resultant synthetic time-series can form new class boundaries and enrich the training dataset. In this work, the comparative evaluation of the proposed augmentation method against related techniques on representative multivariate time-series datasets is presented. The performance of methods is examined using the nearest neighbor classifier with the dynamic time warping (NN-DTW), LogDet divergence-based metric learning with triplet constraints (LDMLT), and the recently introduced time-series cluster kernel (NN-TCK). The impact of the augmentation on the classification performance is investigated, taking into account entire datasets and cases with a small number of training examples. The extensive evaluation reveals that the introduced method outperforms related augmentation algorithms in terms of the obtained classification accuracy.},
	article-number = {98},
	author = {Kamycki, Krzysztof and Kapuscinski, Tomasz and Oszust, Mariusz},
	doi = {10.3390/s20010098},
	issn = {1424-8220},
	journal = {Sensors},
	number = {1},
	pubmedid = {31877970},
	title = {Data Augmentation with Suboptimal Warping for Time-Series Classification},
	url = {https://www.mdpi.com/1424-8220/20/1/98},
	volume = {20},
	year = {2020},
	bdsk-url-1 = {https://www.mdpi.com/1424-8220/20/1/98},
	bdsk-url-2 = {https://doi.org/10.3390/s20010098}}


% RGW (Um), RGWs, DGW, DGWs - also Um, or survey give better.
@misc{iwana2020timeseriesdataaugmentation,
      title={Time Series Data Augmentation for Neural Networks by Time Warping with a Discriminative Teacher}, 
      author={Brian Kenji Iwana and Seiichi Uchida},
      year={2020},
      eprint={2004.08780},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2004.08780}, 
}

% Iwana
@article{10.1371/journal.pone.0254841,
	abstract = {In recent times, deep artificial neural networks have achieved many successes in pattern recognition. Part of this success can be attributed to the reliance on big data to increase generalization. However, in the field of time series recognition, many datasets are often very small. One method of addressing this problem is through the use of data augmentation. In this paper, we survey data augmentation techniques for time series and their application to time series classification with neural networks. We propose a taxonomy and outline the four families in time series data augmentation, including transformation-based methods, pattern mixing, generative models, and decomposition methods. Furthermore, we empirically evaluate 12 time series data augmentation methods on 128 time series classification datasets with six different types of neural networks. Through the results, we are able to analyze the characteristics, advantages and disadvantages, and recommendations of each data augmentation method. This survey aims to help in the selection of time series data augmentation for neural network applications.},
	author = {Iwana, Brian Kenji AND Uchida, Seiichi},
	doi = {10.1371/journal.pone.0254841},
	journal = {PLOS ONE},
	month = {07},
	number = {7},
	pages = {1-32},
	publisher = {Public Library of Science},
	title = {An empirical survey of data augmentation for time series classification with neural networks},
	url = {https://doi.org/10.1371/journal.pone.0254841},
	volume = {16},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1371/journal.pone.0254841}}



% shapeDTW
@article{ZHAO2018171,
	abstract = {Dynamic Time Warping (DTW) is an algorithm to align temporal sequences with possible local non-linear distortions, and has been widely applied to audio, video and graphics data alignments. DTW is essentially a point-to-point matching method under some boundary and temporal consistency constraints. Although DTW obtains a global optimal solution, it does not necessarily achieve locally sensible matchings. Concretely, two temporal points with entirely dissimilar local structures may be matched by DTW. To address this problem, we propose an improved alignment algorithm, named shape Dynamic Time Warping (shapeDTW), which enhances DTW by taking point-wise local structural information into consideration. shapeDTW is inherently a DTW algorithm, but additionally attempts to pair locally similar structures and to avoid matching points with distinct neighborhood structures. We apply shapeDTW to align audio signal pairs having ground-truth alignments, as well as artificially simulated pairs of aligned sequences, and obtain quantitatively much lower alignment errors than DTW and its two variants. When shapeDTW is used as a distance measure in a nearest neighbor classifier (NN-shapeDTW) to classify time series, it beats DTW on 64 out of 84 UCR time series datasets, with significantly improved classification accuracies. By using a properly designed local structure descriptor, shapeDTW improves accuracies by more than 10% on 18 datasets. To the best of our knowledge, shapeDTW is the first distance measure under the nearest neighbor classifier scheme to significantly outperform DTW, which had been widely recognized as the best distance measure to date. Our code is publicly accessible at: https://github.com/jiapingz/shapeDTW.},
	author = {Jiaping Zhao and Laurent Itti},
	doi = {https://doi.org/10.1016/j.patcog.2017.09.020},
	issn = {0031-3203},
	journal = {Pattern Recognition},
	keywords = {Dynamic Time Warping, Sequence alignment, Time series classification},
	pages = {171-184},
	title = {shapeDTW: Shape Dynamic Time Warping},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320317303710},
	volume = {74},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0031320317303710},
	bdsk-url-2 = {https://doi.org/10.1016/j.patcog.2017.09.020}}


% LSTM-based GAN
@INPROCEEDINGS{8512396,
  author={Haradal, Shota and Hayashi, Hideaki and Uchida, Seiichi},
  booktitle={2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={Biosignal Data Augmentation Based on Generative Adversarial Networks}, 
  year={2018},
  volume={},
  number={},
  pages={368-371},
  keywords={Training data;Gallium nitride;Generators;Electrocardiography;Electroencephalography;Training;Data models},
  doi={10.1109/EMBC.2018.8512396}}


% TCGAN
@misc{ramponi2019tcganconditionalgenerativeadversarial,
      title={T-CGAN: Conditional Generative Adversarial Network for Data Augmentation in Noisy Time Series with Irregular Sampling}, 
      author={Giorgia Ramponi and Pavlos Protopapas and Marco Brambilla and Ryan Janssen},
      year={2019},
      eprint={1811.08295},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1811.08295}, 
}

% Conditional GANs
@misc{mirza2014conditionalgenerativeadversarialnets,
      title={Conditional Generative Adversarial Nets}, 
      author={Mehdi Mirza and Simon Osindero},
      year={2014},
      eprint={1411.1784},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1411.1784}, 
}

% GAN survey
@INPROCEEDINGS{9003933,
  author={Sheng, Peiyao and Yang, Zhuolin and Qian, Yanmin},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={GANs for Children: A Generative Data Augmentation Strategy for Children Speech Recognition}, 
  year={2019},
  volume={},
  number={},
  pages={129-135},
  keywords={Gallium nitride;Speech recognition;Acoustics;Data models;Training;Generative adversarial networks;Generators;children speech recognition;data augmentation;generative adversarial networks},
  doi={10.1109/ASRU46091.2019.9003933}}






% Patch Shuffle
@misc{kang2017patchshuffleregularization,
      title={PatchShuffle Regularization}, 
      author={Guoliang Kang and Xuanyi Dong and Liang Zheng and Yi Yang},
      year={2017},
      eprint={1707.07103},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1707.07103}, 
}

% PatchMix
@article{hong2024patchmix,
  title={PatchMix: patch-level mixup for data augmentation in convolutional neural networks},
  author={Hong, Y. and Chen, Y.},
  journal={Knowledge and Information Systems},
  volume={66},
  pages={3855--3881},
  year={2024},
  publisher={Springer},
  doi={10.1007/s10115-024-02141-3},
  url={https://doi.org/10.1007/s10115-024-02141-3}
}





% RobustSTL
@misc{wen2018robuststlrobustseasonaltrenddecomposition,
      title={RobustSTL: A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series}, 
      author={Qingsong Wen and Jingkun Gao and Xiaomin Song and Liang Sun and Huan Xu and Shenghuo Zhu},
      year={2018},
      eprint={1812.01767},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1812.01767}, 
}







% MODELS:





% PatchTST
@misc{nie2023timeseriesworth64,
      title={A Time Series is Worth 64 Words: Long-term Forecasting with Transformers}, 
      author={Yuqi Nie and Nam H. Nguyen and Phanwadee Sinthong and Jayant Kalagnanam},
      year={2023},
      eprint={2211.14730},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.14730}, 
}




% DATASETS:

% Informer
@misc{zhou2021informerefficienttransformerlong,
      title={Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting}, 
      author={Haoyi Zhou and Shanghang Zhang and Jieqi Peng and Shuai Zhang and Jianxin Li and Hui Xiong and Wancai Zhang},
      year={2021},
      eprint={2012.07436},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2012.07436}, 
}

% Autoformer
@misc{wu2022autoformerdecompositiontransformersautocorrelation,
      title={Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting}, 
      author={Haixu Wu and Jiehui Xu and Jianmin Wang and Mingsheng Long},
      year={2022},
      eprint={2106.13008},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.13008}, 
}

@misc{lai2018modelinglongshorttermtemporal,
      title={Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks}, 
      author={Guokun Lai and Wei-Cheng Chang and Yiming Yang and Hanxiao Liu},
      year={2018},
      eprint={1703.07015},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1703.07015}, 
}

@misc{liu2022scinettimeseriesmodeling,
      title={SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction}, 
      author={Minhao Liu and Ailing Zeng and Muxi Chen and Zhijian Xu and Qiuxia Lai and Lingna Ma and Qiang Xu},
      year={2022},
      eprint={2106.09305},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.09305}, 
}


@misc{UCRArchive2018,
        title = {The UCR Time Series Classification Archive},
        author = {Dau, Hoang Anh and Keogh Eamonn and Kamgar Kaveh and Yeh Chin-Chia Michael and Zhu Yan and Gharghabi Shaghayegh and Ratanamahatana Chotirat Ann and Yanping and Hu Bing and Begum Nurjahan and Bagnall Anthony and Mueen Abdullah and Batista Gustavo and Hexagon-ML},
        year = {2018},
        month = {October},
        url ={https://www.cs.ucr.edu/~eamonn/time_series_data_2018/},
    }

% UEA
@misc{bagnall2018ueamultivariatetimeseries,
      title={The UEA multivariate time series classification archive, 2018}, 
      author={Anthony Bagnall and Hoang Anh Dau and Jason Lines and Michael Flynn and James Large and Aaron Bostrom and Paul Southam and Eamonn Keogh},
      year={2018},
      eprint={1811.00075},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1811.00075}, 
}

% TiDE
@misc{das2024longtermforecastingtidetimeseries,
      title={Long-term Forecasting with TiDE: Time-series Dense Encoder}, 
      author={Abhimanyu Das and Weihao Kong and Andrew Leach and Shaan Mathur and Rajat Sen and Rose Yu},
      year={2024},
      eprint={2304.08424},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2304.08424}, 
}


% TSMixer
@misc{chen2023tsmixerallmlparchitecturetime,
      title={TSMixer: An All-MLP Architecture for Time Series Forecasting}, 
      author={Si-An Chen and Chun-Liang Li and Nate Yoder and Sercan O. Arik and Tomas Pfister},
      year={2023},
      eprint={2303.06053},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.06053}, 
}


% DLinear
@misc{zeng2022transformerseffectivetimeseries,
      title={Are Transformers Effective for Time Series Forecasting?}, 
      author={Ailing Zeng and Muxi Chen and Lei Zhang and Qiang Xu},
      year={2022},
      eprint={2205.13504},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2205.13504}, 
}

% LightTS
@misc{zhang2022morefastmultivariatetime,
      title={Less Is More: Fast Multivariate Time Series Forecasting with Light Sampling-oriented MLP Structures}, 
      author={Tianping Zhang and Yizhuo Zhang and Wei Cao and Jiang Bian and Xiaohan Yi and Shun Zheng and Jian Li},
      year={2022},
      eprint={2207.01186},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2207.01186}, 
}

% additional:

@article{gchron-5-263-2023,
	author = {Lipp, A. and Vermeesch, P.},
	doi = {10.5194/gchron-5-263-2023},
	journal = {Geochronology},
	number = {1},
	pages = {263--270},
	title = {Short communication: The Wasserstein distance as a dissimilarity metric for comparing detrital age spectra and other geological distributions},
	url = {https://gchron.copernicus.org/articles/5/263/2023/},
	volume = {5},
	year = {2023},
	bdsk-url-1 = {https://gchron.copernicus.org/articles/5/263/2023/},
	bdsk-url-2 = {https://doi.org/10.5194/gchron-5-263-2023}}



@InProceedings{Gong_2021_CVPR,
    author    = {Gong, Chengyue and Wang, Dilin and Li, Meng and Chandra, Vikas and Liu, Qiang},
    title     = {KeepAugment: A Simple Information-Preserving Data Augmentation Approach},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {1055-1064}
}

@misc{wei2020circumventingoutliersautoaugmentknowledge,
      title={Circumventing Outliers of AutoAugment with Knowledge Distillation}, 
      author={Longhui Wei and An Xiao and Lingxi Xie and Xin Chen and Xiaopeng Zhang and Qi Tian},
      year={2020},
      eprint={2003.11342},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2003.11342}, 
}

% gnns:

@misc{yi2023fouriergnnrethinkingmultivariatetime,
      title={FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure Graph Perspective}, 
      author={Kun Yi and Qi Zhang and Wei Fan and Hui He and Liang Hu and Pengyang Wang and Ning An and Longbing Cao and Zhendong Niu},
      year={2023},
      eprint={2311.06190},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.06190}, 
}


@inproceedings{NEURIPS2020_ce1aad92,
	author = {BAI, LEI and Yao, Lina and Li, Can and Wang, Xianzhi and Wang, Can},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
	pages = {17804--17815},
	publisher = {Curran Associates, Inc.},
	title = {Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting},
	url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/ce1aad92b939420fc17005e5461e6f48-Paper.pdf},
	volume = {33},
	year = {2020},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2020/file/ce1aad92b939420fc17005e5461e6f48-Paper.pdf}}

@misc{cao2021spectraltemporalgraphneural,
      title={Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting}, 
      author={Defu Cao and Yujing Wang and Juanyong Duan and Ce Zhang and Xia Zhu and Conguri Huang and Yunhai Tong and Bixiong Xu and Jing Bai and Jie Tong and Qi Zhang},
      year={2021},
      eprint={2103.07719},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.07719}, 
}

% cylcenet
@misc{lin2024cyclenetenhancingtimeseries,
      title={CycleNet: Enhancing Time Series Forecasting through Modeling Periodic Patterns}, 
      author={Shengsheng Lin and Weiwei Lin and Xinyi Hu and Wentai Wu and Ruichao Mo and Haocheng Zhong},
      year={2024},
      eprint={2409.18479},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.18479}, 
}

@misc{lin2025temporalquerynetworkefficient,
      title={Temporal Query Network for Efficient Multivariate Time Series Forecasting}, 
      author={Shengsheng Lin and Haojun Chen and Haijie Wu and Chunyun Qiu and Weiwei Lin},
      year={2025},
      eprint={2505.12917},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2505.12917}, 
}

% SFCC

@article{sfccYang2023,
  author    = {Wenbo Yang and Jidong Yuan and Xiaokang Wang},
  title     = {SFCC: Data Augmentation with Stratified Fourier Coefficients Combination for Time Series Classification},
  journal   = {Neural Processing Letters},
  volume    = {55},
  number    = {2},
  pages     = {1833--1846},
  year      = {2023},
  doi       = {10.1007/s11063-022-10965-9},
  url       = {https://doi.org/10.1007/s11063-022-10965-9},
  issn      = {1573-773X},
  abstract  = {Deep neural networks (DNNs) have shown remarkable performance in time series classification tasks. However, the DNNs rely on a mass of data, which may not accumulate in real scenarios. As such, researchers investigate data augmentation methods to solve the scarcity of labeled data. Some of them, such as the rotation, that borrowed from the computer vision are not applicable due to the unique property of time series data. Besides, existing frequency-based methods applied for audio and speech recognition generate new samples by changing original frequency information, which may introduce unreasonable variation. In this paper, we propose a novel time series data augmentation method called Stratified Fourier Coefficients Combination (SFCC). SFCC retains and combines the original Fourier coefficients to augment the time series datasets. First, we transform data into the frequency domain using the discrete Fourier transform (DFT). To maintain the initial data distribution, we stratify the coefficients into several groups and then randomly select the groups to concatenate the coefficients. Finally, a new sample is generated through inverse DFT. The experiments demonstrate that the augmentation by SFCC can effectively improve the performance of the DNNs and achieve state-of-the-art results compared with the other 12 benchmarking methods.}
}


% TS2Vec
@article{Yue_Wang_Duan_Yang_Huang_Tong_Xu_2022,
	abstractnote = {This paper presents TS2Vec, a universal framework for learning representations of time series in an arbitrary semantic level. Unlike existing methods, TS2Vec performs contrastive learning in a hierarchical way over augmented context views, which enables a robust contextual representation for each timestamp. Furthermore, to obtain the representation of an arbitrary sub-sequence in the time series, we can apply a simple aggregation over the representations of corresponding timestamps. We conduct extensive experiments on time series classification tasks to evaluate the quality of time series representations. As a result, TS2Vec achieves significant improvement over existing SOTAs of unsupervised time series representation on 125 UCR datasets and 29 UEA datasets. The learned timestamp-level representations also achieve superior results in time series forecasting and anomaly detection tasks. A linear regression trained on top of the learned representations outperforms previous SOTAs of time series forecasting. Furthermore, we present a simple way to apply the learned representations for unsupervised anomaly detection, which establishes SOTA results in the literature. The source code is publicly available at https://github.com/yuezhihan/ts2vec.},
	author = {Yue, Zhihan and Wang, Yujing and Duan, Juanyong and Yang, Tianmeng and Huang, Congrui and Tong, Yunhai and Xu, Bixiong},
	doi = {10.1609/aaai.v36i8.20881},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	month = {Jun.},
	number = {8},
	pages = {8980-8987},
	title = {TS2Vec: Towards Universal Representation of Time Series},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/20881},
	volume = {36},
	year = {2022},
	bdsk-url-1 = {https://ojs.aaai.org/index.php/AAAI/article/view/20881},
	bdsk-url-2 = {https://doi.org/10.1609/aaai.v36i8.20881}}


@misc{lan2024enhancingtimeseriescontrastive,
      title={Towards Enhancing Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach}, 
      author={Xiang Lan and Hanshu Yan and Shenda Hong and Mengling Feng},
      year={2024},
      eprint={2302.03357},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.03357}, 
}

% TF-C
@misc{zhang2022selfsupervisedcontrastivepretrainingtime,
      title={Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency}, 
      author={Xiang Zhang and Ziyuan Zhao and Theodoros Tsiligkaridis and Marinka Zitnik},
      year={2022},
      eprint={2206.08496},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.08496}, 
}



@article{en16020764,
	abstract = {The diagnostic fracture injection test (DFIT) is widely used to obtain the fracture closure pressure, reservoir permeability, and reservoir pressure. Conventional methods for analyzing DFIT are based on the assumption that a vertical well is drilled in ultra-low permeability reservoirs with potential multiple closures but fails to consider horizontal wells. There is still significant debate about the rigorousness and validity of these techniques due to the complexity of the hydraulic fracture opening and closure process and assumptions of conventional fracture detection methods. The paper introduces a new method for detecting fracture closure pressure using the continuous wavelet transform (CWT). The new method aims to decompose the pressure fall-off signal into multiple levels with different frequencies using the CWT. This ``short wavy'' function is stretched or compressed and placed at many positions along the signal to be analyzed. The wavelet then convoluted the signal yielding a wavelet coefficient value. The signal energy is observed during the fracture closure process (pressure fall-off) and the fracture closure event is identified when the signal energy stabilizes to a minimum level. A predefined simple commercial fracture simulation case with known fracture closure, flow regime modeling, and actual field cases was used to validate the new methodology.},
	article-number = {764},
	author = {Gabry, Mohamed Adel and Eltaleb, Ibrahim and Soliman, Mohamed Y. and Farouq-Ali, Syed M.},
	doi = {10.3390/en16020764},
	issn = {1996-1073},
	journal = {Energies},
	number = {2},
	title = {A New Technique for Estimating Stress from Fracture Injection Tests Using Continuous Wavelet Transform},
	url = {https://www.mdpi.com/1996-1073/16/2/764},
	volume = {16},
	year = {2023},
	bdsk-url-1 = {https://www.mdpi.com/1996-1073/16/2/764},
	bdsk-url-2 = {https://doi.org/10.3390/en16020764}}



@article{Iglesias2023,
  author    = {Guillermo Iglesias and Edgar Talavera and {\'A}ngel Gonz{\'a}lez-Prieto and Alberto Mozo and Sandra G{\'o}mez-Canaval},
  title     = {Data Augmentation techniques in time series domain: a survey and taxonomy},
  journal   = {Neural Computing and Applications},
  volume    = {35},
  number    = {14},
  pages     = {10123--10145},
  year      = {2023},
  doi       = {10.1007/s00521-023-08459-3},
  url       = {https://doi.org/10.1007/s00521-023-08459-3},
  issn      = {1433-3058},
  abstract  = {With the latest advances in deep learning-based generative models, it has not taken long to take advantage of their remarkable performance in the area of time series. Deep neural networks used to work with time series heavily depend on the size and consistency of the datasets used in training. These features are not usually abundant in the real world, where they are usually limited and often have constraints that must be guaranteed. Therefore, an effective way to increase the amount of data is by using data augmentation techniques, either by adding noise or permutations and by generating new synthetic data. This work systematically reviews the current state of the art in the area to provide an overview of all available algorithms and proposes a taxonomy of the most relevant research. The efficiency of the different variants will be evaluated as a central part of the process, as well as the different metrics to evaluate the performance and the main problems concerning each model will be analysed. The ultimate aim of this study is to provide a summary of the evolution and performance of areas that produce better results to guide future researchers in this field.}
}
